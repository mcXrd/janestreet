{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>enc_feature_0</th>\n",
       "      <th>enc_feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>-1.154506</td>\n",
       "      <td>1.143241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1.750787</td>\n",
       "      <td>-0.484918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1.676534</td>\n",
       "      <td>-0.037986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-3.441493</td>\n",
       "      <td>-0.615681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>-0.633096</td>\n",
       "      <td>0.858466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>-0.001428</td>\n",
       "      <td>-0.004994</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>-0.857181</td>\n",
       "      <td>0.529766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030492</td>\n",
       "      <td>4.015928</td>\n",
       "      <td>-0.616074</td>\n",
       "      <td>1.373682</td>\n",
       "      <td>-0.063830</td>\n",
       "      <td>3.991392</td>\n",
       "      <td>-0.380230</td>\n",
       "      <td>2.495774</td>\n",
       "      <td>-0.706637</td>\n",
       "      <td>1.326145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>-0.173674</td>\n",
       "      <td>0.682367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045765</td>\n",
       "      <td>2.741755</td>\n",
       "      <td>0.402868</td>\n",
       "      <td>5.051385</td>\n",
       "      <td>0.562242</td>\n",
       "      <td>4.014664</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>2.783974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.861720</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>-2.054637</td>\n",
       "      <td>-0.022095</td>\n",
       "      <td>...</td>\n",
       "      <td>3.900376</td>\n",
       "      <td>4.012600</td>\n",
       "      <td>1.511398</td>\n",
       "      <td>0.223437</td>\n",
       "      <td>3.263071</td>\n",
       "      <td>3.642822</td>\n",
       "      <td>3.165782</td>\n",
       "      <td>1.600927</td>\n",
       "      <td>2.110370</td>\n",
       "      <td>0.620644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181539</td>\n",
       "      <td>-0.009904</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.701830</td>\n",
       "      <td>1.884682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.179935</td>\n",
       "      <td>2.398382</td>\n",
       "      <td>2.975455</td>\n",
       "      <td>2.099968</td>\n",
       "      <td>4.687357</td>\n",
       "      <td>2.076800</td>\n",
       "      <td>5.053417</td>\n",
       "      <td>2.605069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.422520</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.010871</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>-0.015188</td>\n",
       "      <td>-1.938022</td>\n",
       "      <td>-0.147814</td>\n",
       "      <td>...</td>\n",
       "      <td>1.829552</td>\n",
       "      <td>6.352524</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>1.295183</td>\n",
       "      <td>1.632724</td>\n",
       "      <td>6.342713</td>\n",
       "      <td>1.919200</td>\n",
       "      <td>4.543165</td>\n",
       "      <td>0.951596</td>\n",
       "      <td>2.796835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  date     weight    resp_1    resp_2    resp_3    resp_4  \\\n",
       "0             0   0.0   0.000000  0.009916  0.014079  0.008773  0.001390   \n",
       "1             1   0.0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114   \n",
       "2             2   0.0   0.000000  0.025134  0.027607  0.033406  0.034380   \n",
       "3             3   0.0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476   \n",
       "4             4   0.0   0.138531  0.001252  0.002165 -0.001215 -0.006219   \n",
       "..          ...   ...        ...       ...       ...       ...       ...   \n",
       "195         195   0.0   0.000000  0.001245  0.003061 -0.001428 -0.004994   \n",
       "196         196   0.0   0.000000  0.001745  0.004459  0.002032  0.001878   \n",
       "197         197   0.0   1.861720 -0.000892  0.002704  0.001906  0.005911   \n",
       "198         198   0.0   0.181539 -0.009904 -0.010052 -0.004704  0.017605   \n",
       "199         199   0.0   2.422520 -0.001563 -0.004381 -0.010871 -0.016949   \n",
       "\n",
       "         resp  enc_feature_0  enc_feature_1  ...  feature_120  feature_121  \\\n",
       "0    0.006270      -1.154506       1.143241  ...     0.000000     0.000000   \n",
       "1   -0.009792      -1.750787      -0.484918  ...     0.000000     0.000000   \n",
       "2    0.023970      -1.676534      -0.037986  ...     0.000000     0.000000   \n",
       "3   -0.003200      -3.441493      -0.615681  ...     0.000000     0.000000   \n",
       "4   -0.002604      -0.633096       0.858466  ...     0.000000     0.000000   \n",
       "..        ...            ...            ...  ...          ...          ...   \n",
       "195 -0.000836      -0.857181       0.529766  ...    -0.030492     4.015928   \n",
       "196  0.005651      -0.173674       0.682367  ...     0.000000     0.000000   \n",
       "197  0.005989      -2.054637      -0.022095  ...     3.900376     4.012600   \n",
       "198  0.006678       0.701830       1.884682  ...     0.000000     0.000000   \n",
       "199 -0.015188      -1.938022      -0.147814  ...     1.829552     6.352524   \n",
       "\n",
       "     feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "0       1.168391     8.313583     1.782433    14.018213     2.653056   \n",
       "1      -1.178850     1.777472    -0.915458     2.831612    -1.417010   \n",
       "2       6.115747     9.667908     5.542871    11.671595     7.281757   \n",
       "3       2.838853     0.499251     3.033732     1.513488     4.397532   \n",
       "4       0.344850     4.101145     0.614252     6.623456     0.800129   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "195    -0.616074     1.373682    -0.063830     3.991392    -0.380230   \n",
       "196     0.045765     2.741755     0.402868     5.051385     0.562242   \n",
       "197     1.511398     0.223437     3.263071     3.642822     3.165782   \n",
       "198     4.179935     2.398382     2.975455     2.099968     4.687357   \n",
       "199     0.122395     1.295183     1.632724     6.342713     1.919200   \n",
       "\n",
       "     feature_127  feature_128  feature_129  \n",
       "0      12.600292     2.301488    11.445807  \n",
       "1       2.297459    -1.304614     1.898684  \n",
       "2      10.060014     6.638248     9.427299  \n",
       "3       1.266037     3.856384     1.013469  \n",
       "4       5.233243     0.362636     3.926633  \n",
       "..           ...          ...          ...  \n",
       "195     2.495774    -0.706637     1.326145  \n",
       "196     4.014664     0.119955     2.783974  \n",
       "197     1.600927     2.110370     0.620644  \n",
       "198     2.076800     5.053417     2.605069  \n",
       "199     4.543165     0.951596     2.796835  \n",
       "\n",
       "[200 rows x 188 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/vaclavmatejka/devel/janestreet/model_8_SDAE_emphasized_loss/encoded.csv\", nrows=324)\n",
    "df.loc[400:,\"enc_feature_0\":\"enc_feature_49\"]\n",
    "strip = 1 + df.shape[0] % 200\n",
    "df.loc[:df.shape[0]-strip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1638,  0.1434,  0.7901])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1.0,2000.0,3.0])\n",
    "noise = torch.randn_like(t)\n",
    "noise.multiply(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = 1000\n",
    "df = pd.read_csv(\"/home/vaclavmatejka/devel/janestreet/jane-street-market-prediction/train.csv\", nrows=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df.loc[df['resp'] <= 0, 'trade'] = 0\n",
    "df.loc[df['resp'] > 0, 'trade'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004402</td>\n",
       "      <td>-0.008527</td>\n",
       "      <td>-0.025084</td>\n",
       "      <td>-0.026695</td>\n",
       "      <td>-0.019317</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.038037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.830452</td>\n",
       "      <td>-1.222913</td>\n",
       "      <td>-0.064535</td>\n",
       "      <td>0.873099</td>\n",
       "      <td>-0.033574</td>\n",
       "      <td>0.686286</td>\n",
       "      <td>-0.658388</td>\n",
       "      <td>-0.576456</td>\n",
       "      <td>7573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7931</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980720</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.451098</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.878457</td>\n",
       "      <td>-1.679667</td>\n",
       "      <td>-1.111006</td>\n",
       "      <td>-1.041194</td>\n",
       "      <td>-1.845241</td>\n",
       "      <td>-0.843076</td>\n",
       "      <td>-1.612836</td>\n",
       "      <td>-0.763775</td>\n",
       "      <td>7931</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2390</td>\n",
       "      <td>0</td>\n",
       "      <td>10.469229</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.006666</td>\n",
       "      <td>-0.013447</td>\n",
       "      <td>-0.009634</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.135190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496450</td>\n",
       "      <td>-0.252105</td>\n",
       "      <td>-0.770537</td>\n",
       "      <td>-1.946120</td>\n",
       "      <td>-1.160092</td>\n",
       "      <td>-1.329745</td>\n",
       "      <td>-0.865972</td>\n",
       "      <td>-0.913463</td>\n",
       "      <td>2390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327308</td>\n",
       "      <td>-0.006592</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.032523</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>1</td>\n",
       "      <td>4.628062</td>\n",
       "      <td>...</td>\n",
       "      <td>4.258689</td>\n",
       "      <td>0.545369</td>\n",
       "      <td>2.595033</td>\n",
       "      <td>-0.850193</td>\n",
       "      <td>3.537147</td>\n",
       "      <td>-0.719482</td>\n",
       "      <td>3.897598</td>\n",
       "      <td>-0.088774</td>\n",
       "      <td>9875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.160377</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.070417</td>\n",
       "      <td>-0.476946</td>\n",
       "      <td>-1.198019</td>\n",
       "      <td>-2.238900</td>\n",
       "      <td>-1.792717</td>\n",
       "      <td>-1.323538</td>\n",
       "      <td>-1.244437</td>\n",
       "      <td>-0.519089</td>\n",
       "      <td>3692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.290936</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.019703</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306043</td>\n",
       "      <td>...</td>\n",
       "      <td>4.214743</td>\n",
       "      <td>2.063822</td>\n",
       "      <td>3.263793</td>\n",
       "      <td>2.107301</td>\n",
       "      <td>4.698732</td>\n",
       "      <td>1.757803</td>\n",
       "      <td>4.615820</td>\n",
       "      <td>1.905804</td>\n",
       "      <td>8882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7506</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>-0.003088</td>\n",
       "      <td>-0.002118</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>-0.005047</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165269</td>\n",
       "      <td>0.952018</td>\n",
       "      <td>-0.573792</td>\n",
       "      <td>-0.219193</td>\n",
       "      <td>-0.783141</td>\n",
       "      <td>-0.018819</td>\n",
       "      <td>-0.334602</td>\n",
       "      <td>0.636739</td>\n",
       "      <td>7506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637961</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.013917</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>1</td>\n",
       "      <td>2.780710</td>\n",
       "      <td>...</td>\n",
       "      <td>4.642466</td>\n",
       "      <td>2.840470</td>\n",
       "      <td>4.100702</td>\n",
       "      <td>3.537450</td>\n",
       "      <td>4.956971</td>\n",
       "      <td>2.309757</td>\n",
       "      <td>4.489792</td>\n",
       "      <td>2.120206</td>\n",
       "      <td>136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524943</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>-0.028579</td>\n",
       "      <td>-0.038777</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.881692</td>\n",
       "      <td>0.119740</td>\n",
       "      <td>2.341829</td>\n",
       "      <td>1.415651</td>\n",
       "      <td>2.555142</td>\n",
       "      <td>0.303994</td>\n",
       "      <td>1.680772</td>\n",
       "      <td>-0.358917</td>\n",
       "      <td>1141</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069982</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>-0.008965</td>\n",
       "      <td>-0.005460</td>\n",
       "      <td>1</td>\n",
       "      <td>2.693218</td>\n",
       "      <td>...</td>\n",
       "      <td>3.254565</td>\n",
       "      <td>0.884285</td>\n",
       "      <td>1.756823</td>\n",
       "      <td>-0.491352</td>\n",
       "      <td>2.581434</td>\n",
       "      <td>-0.329042</td>\n",
       "      <td>3.161932</td>\n",
       "      <td>0.434131</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  date     weight    resp_1    resp_2    resp_3    resp_4  \\\n",
       "0      7573     1   0.000000 -0.004402 -0.008527 -0.025084 -0.026695   \n",
       "1      7931     1   0.980720  0.002422 -0.000294  0.003540  0.007488   \n",
       "2      2390     0  10.469229 -0.000664 -0.002001 -0.006666 -0.013447   \n",
       "3      9875     1   0.327308 -0.006592  0.000331  0.007391  0.032523   \n",
       "4      3692     0   0.000000  0.000415  0.000405  0.002584 -0.000807   \n",
       "...     ...   ...        ...       ...       ...       ...       ...   \n",
       "9995   8882     1   0.290936  0.000292  0.002466  0.005289  0.019703   \n",
       "9996   7506     1   0.248309 -0.002285 -0.003088 -0.002118 -0.005039   \n",
       "9997    136     0   0.637961  0.005205  0.000224  0.002150 -0.013917   \n",
       "9998   1141     0   0.524943  0.005839  0.012180  0.025380 -0.028579   \n",
       "9999   4925     0   0.069982  0.001698  0.002039 -0.001221 -0.008965   \n",
       "\n",
       "          resp  feature_0  feature_1  ...  feature_122  feature_123  \\\n",
       "0    -0.019317         -1  -0.038037  ...    -0.830452    -1.222913   \n",
       "1     0.002344         -1   0.451098  ...    -1.878457    -1.679667   \n",
       "2    -0.009634          1  -1.135190  ...    -0.496450    -0.252105   \n",
       "3     0.027312          1   4.628062  ...     4.258689     0.545369   \n",
       "4    -0.005772         -1  -1.160377  ...    -1.070417    -0.476946   \n",
       "...        ...        ...        ...  ...          ...          ...   \n",
       "9995  0.019392          1  -0.306043  ...     4.214743     2.063822   \n",
       "9996 -0.005047         -1  -3.172026  ...    -0.165269     0.952018   \n",
       "9997 -0.016805          1   2.780710  ...     4.642466     2.840470   \n",
       "9998 -0.038777          1  -3.172026  ...     1.881692     0.119740   \n",
       "9999 -0.005460          1   2.693218  ...     3.254565     0.884285   \n",
       "\n",
       "      feature_124  feature_125  feature_126  feature_127  feature_128  \\\n",
       "0       -0.064535     0.873099    -0.033574     0.686286    -0.658388   \n",
       "1       -1.111006    -1.041194    -1.845241    -0.843076    -1.612836   \n",
       "2       -0.770537    -1.946120    -1.160092    -1.329745    -0.865972   \n",
       "3        2.595033    -0.850193     3.537147    -0.719482     3.897598   \n",
       "4       -1.198019    -2.238900    -1.792717    -1.323538    -1.244437   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995     3.263793     2.107301     4.698732     1.757803     4.615820   \n",
       "9996    -0.573792    -0.219193    -0.783141    -0.018819    -0.334602   \n",
       "9997     4.100702     3.537450     4.956971     2.309757     4.489792   \n",
       "9998     2.341829     1.415651     2.555142     0.303994     1.680772   \n",
       "9999     1.756823    -0.491352     2.581434    -0.329042     3.161932   \n",
       "\n",
       "      feature_129  ts_id  trade  \n",
       "0       -0.576456   7573    0.0  \n",
       "1       -0.763775   7931    1.0  \n",
       "2       -0.913463   2390    0.0  \n",
       "3       -0.088774   9875    1.0  \n",
       "4       -0.519089   3692    0.0  \n",
       "...           ...    ...    ...  \n",
       "9995     1.905804   8882    1.0  \n",
       "9996     0.636739   7506    0.0  \n",
       "9997     2.120206    136    0.0  \n",
       "9998    -0.358917   1141    0.0  \n",
       "9999     0.434131   4925    0.0  \n",
       "\n",
       "[10000 rows x 140 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaneStreetDataset(Dataset):\n",
    "\n",
    "    # Constructor with defult values\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.len = len(self.df)\n",
    "        self.transform = transform\n",
    "\n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = torch.from_numpy(self.df.iloc[index][\"feature_0\":\"feature_129\"].values), torch.tensor(self.df.iloc[index][\"resp\"])\n",
    "        sample = sample[0].to(device), sample[1].to(device)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009634158690232266"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][\"resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -1.13518959e+00, -1.61827057e+00,  4.54450598e-01,\n",
       "        2.80194598e-01,  8.34325776e-01,  6.00991096e-01, -7.52922825e-01,\n",
       "       -7.60245730e-01, -1.26065357e+00, -1.16282365e+00,  3.28691328e-01,\n",
       "        1.57604453e-01, -2.00281266e+00, -1.54143486e+00, -8.06410352e-01,\n",
       "       -1.44557732e+00,  8.54325656e-01,  8.53438605e-01,  2.70115762e-01,\n",
       "        1.22521804e-01,  1.07888779e+00,  4.84688120e-01,  2.30981202e-01,\n",
       "        9.86927946e-02,  2.75536780e-01,  1.03283244e-01, -5.49189303e-01,\n",
       "       -7.48393220e-01, -5.29760682e-01, -4.92395888e-01, -6.75317837e-01,\n",
       "       -1.07180458e+00, -1.06146682e+00, -9.24106051e-01, -7.42370466e-01,\n",
       "       -4.48241035e-01,  1.07317754e+00,  9.00970932e-01, -2.40498460e-01,\n",
       "       -3.47299546e-01,  2.17191018e+00, -3.95957967e-01,  1.14263502e+00,\n",
       "        4.47306184e-01,  5.67436716e-01,  5.70503068e-01,  7.82952089e-01,\n",
       "        4.61510203e-01,  1.99919843e-01,  1.22670170e+00,  2.65245924e+00,\n",
       "        1.34119908e+00, -3.56748341e-01,  1.65067313e-01,  1.81337004e+00,\n",
       "       -4.49947146e-02,  1.99467454e+00,  2.38743882e+00,  2.13005460e+00,\n",
       "       -1.45635570e+00, -1.21888446e+00,  1.67549271e+00,  1.73474684e+00,\n",
       "       -4.30321702e-01,  8.54461748e-01,  7.08229566e-01, -1.07049667e+00,\n",
       "       -1.03096895e+00, -7.27444470e-01, -9.09738630e-01, -9.55175906e-01,\n",
       "        2.43406840e-01, -5.51778306e-01, -9.34265477e-02,  2.22215602e-01,\n",
       "       -5.12737914e-01, -4.76730093e-01,  7.08934320e-01, -7.39138538e-01,\n",
       "       -2.02919110e-01,  4.45906880e-01, -6.94357738e-01, -9.15531721e-01,\n",
       "        3.24548248e-01, -1.23821241e+00, -5.06631054e-02, -3.08182267e-01,\n",
       "       -1.64186017e+00, -1.79339470e-01,  1.14273150e+00, -1.51561349e+00,\n",
       "        4.72040986e-01,  1.93478887e-01, -1.08688642e+00,  7.29592262e-01,\n",
       "        2.44229400e-01,  5.14969891e-01, -1.48970108e-03, -4.58031220e-01,\n",
       "        1.19637572e-01, -1.11841871e-01,  1.17811690e+00,  8.26158486e-01,\n",
       "        4.77704786e-01, -2.85609916e-01,  6.17244401e-01,  8.01955086e-01,\n",
       "        4.22522303e-01, -1.05118881e+00, -1.00639997e-01, -5.72432460e-01,\n",
       "       -1.45037828e+00, -2.03121548e-01,  1.09131958e+00, -2.67911817e-01,\n",
       "        6.23903932e-01, -2.23377279e-01, -6.80334734e-01,  5.80458670e-01,\n",
       "       -8.56725082e-01, -1.78954499e+00, -4.96450008e-01, -2.52105102e-01,\n",
       "       -7.70536965e-01, -1.94612019e+00, -1.16009169e+00, -1.32974511e+00,\n",
       "       -8.65971919e-01, -9.13463219e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][\"feature_0\":\"feature_129\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ae5219358239>:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=130, out_features=500, bias=True)\n",
       "  (1): Dropout(p=0.0, inplace=False)\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Linear(in_features=500, out_features=1000, bias=True)\n",
       "  (5): Dropout(p=0.0, inplace=False)\n",
       "  (6): ReLU()\n",
       "  (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (9): Dropout(p=0.0, inplace=False)\n",
       "  (10): ReLU()\n",
       "  (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (13): Dropout(p=0.0, inplace=False)\n",
       "  (14): ReLU()\n",
       "  (15): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (17): Dropout(p=0.0, inplace=False)\n",
       "  (18): ReLU()\n",
       "  (19): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROPOUT_P = 0.0\n",
    "big_number = 1000\n",
    "small_number = 500\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(130, small_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(small_number),\n",
    "    torch.nn.Linear(small_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, small_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(small_number),\n",
    "    torch.nn.Linear(small_number, 1),\n",
    ")\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "janestreet_train = JaneStreetDataset(df=df.iloc[:-VALIDATION_SIZE])\n",
    "janestreet_validation = JaneStreetDataset(df=df.iloc[-VALIDATION_SIZE:])\n",
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 50\n",
    "LR = 0.05\n",
    "train_loader = torch.utils.data.DataLoader(dataset=janestreet_train, batch_size=BATCH_SIZE, drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=janestreet_validation, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, optimizer, criterion, n_epochs=None):\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.float())\n",
    "            y = y.view(-1, 1).float()\n",
    "            loss = criterion(z, y)\n",
    "            writer.add_scalar(\"Train data\", loss, epoch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.data)\n",
    "        # perform a prediction on the validation data\n",
    "        for x_test, y_test in validation_loader:\n",
    "            model.eval()\n",
    "            z = model(x_test.float())\n",
    "            y = y.view(-1, 1)\n",
    "            loss = criterion(z, y.float())\n",
    "            writer.add_scalar(\"Validation data\", loss, epoch)\n",
    "            accuracy_list.append(loss.data)\n",
    "    return accuracy_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c28e6fbd8523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ea7961b342b8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, validation_loader, optimizer, criterion, n_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-287acf998c17>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"feature_129\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[1;32m   1421\u001b[0m         \u001b[0mCheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;34m'key'\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdesired\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_list, loss_list = train_model(model, train_loader, validation_loader, optimizer, criterion, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=2000\n",
    "#a = torch.from_numpy(df.iloc[index][\"feature_0\":\"feature_129\"].values)\n",
    "a = df.iloc[index][\"feature_0\":\"feature_129\"].values\n",
    "resp = torch.tensor(df.iloc[index][\"resp\"])\n",
    "\n",
    "r = []\n",
    "for one in range(BATCH_SIZE):\n",
    "    r.append(a)\n",
    "r = np.array(r)\n",
    "model_input =torch.from_numpy(r).float().to(device)\n",
    "z = model(model_input)\n",
    "\n",
    "(resp, z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
