{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_feature_40</th>\n",
       "      <th>enc_feature_41</th>\n",
       "      <th>enc_feature_42</th>\n",
       "      <th>enc_feature_43</th>\n",
       "      <th>enc_feature_44</th>\n",
       "      <th>enc_feature_45</th>\n",
       "      <th>enc_feature_46</th>\n",
       "      <th>enc_feature_47</th>\n",
       "      <th>enc_feature_48</th>\n",
       "      <th>enc_feature_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123428</td>\n",
       "      <td>0.628796</td>\n",
       "      <td>-4.023776</td>\n",
       "      <td>-2.183965</td>\n",
       "      <td>-0.077025</td>\n",
       "      <td>-4.211199</td>\n",
       "      <td>1.769949</td>\n",
       "      <td>-1.008828</td>\n",
       "      <td>-0.767571</td>\n",
       "      <td>0.848031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126286</td>\n",
       "      <td>0.982762</td>\n",
       "      <td>-0.533399</td>\n",
       "      <td>-0.803045</td>\n",
       "      <td>-1.049025</td>\n",
       "      <td>-1.367514</td>\n",
       "      <td>0.530526</td>\n",
       "      <td>-1.428573</td>\n",
       "      <td>0.224584</td>\n",
       "      <td>0.032676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.537209</td>\n",
       "      <td>0.427623</td>\n",
       "      <td>-0.817448</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>-2.020541</td>\n",
       "      <td>-2.091881</td>\n",
       "      <td>-0.527815</td>\n",
       "      <td>0.721394</td>\n",
       "      <td>1.850761</td>\n",
       "      <td>3.646196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.342461</td>\n",
       "      <td>1.185159</td>\n",
       "      <td>0.678673</td>\n",
       "      <td>1.851038</td>\n",
       "      <td>-2.856198</td>\n",
       "      <td>-0.807522</td>\n",
       "      <td>-0.994373</td>\n",
       "      <td>-0.755705</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>2.259202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.358059</td>\n",
       "      <td>-2.763735</td>\n",
       "      <td>-0.889712</td>\n",
       "      <td>0.208458</td>\n",
       "      <td>-2.821480</td>\n",
       "      <td>0.922953</td>\n",
       "      <td>-1.532228</td>\n",
       "      <td>-0.317601</td>\n",
       "      <td>0.308245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390395</th>\n",
       "      <td>3595</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-0.005755</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>-0.002785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.544545</td>\n",
       "      <td>...</td>\n",
       "      <td>2.371367</td>\n",
       "      <td>1.537548</td>\n",
       "      <td>1.859324</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>2.582138</td>\n",
       "      <td>2.825742</td>\n",
       "      <td>-0.177744</td>\n",
       "      <td>1.865541</td>\n",
       "      <td>-2.093856</td>\n",
       "      <td>-2.508276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390396</th>\n",
       "      <td>3596</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.501201</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>-0.077939</td>\n",
       "      <td>-0.085305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.677197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737484</td>\n",
       "      <td>-0.531420</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>-0.057722</td>\n",
       "      <td>0.434626</td>\n",
       "      <td>-0.072989</td>\n",
       "      <td>-1.063528</td>\n",
       "      <td>-0.836696</td>\n",
       "      <td>1.560309</td>\n",
       "      <td>-0.446988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390397</th>\n",
       "      <td>3597</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.128814</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.031198</td>\n",
       "      <td>0.031656</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.727401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164722</td>\n",
       "      <td>0.643131</td>\n",
       "      <td>0.073588</td>\n",
       "      <td>4.158679</td>\n",
       "      <td>-0.103347</td>\n",
       "      <td>1.852715</td>\n",
       "      <td>-0.158158</td>\n",
       "      <td>2.461866</td>\n",
       "      <td>-2.006335</td>\n",
       "      <td>1.108660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390398</th>\n",
       "      <td>3598</td>\n",
       "      <td>499.0</td>\n",
       "      <td>13.542308</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.746609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125191</td>\n",
       "      <td>2.172657</td>\n",
       "      <td>2.873001</td>\n",
       "      <td>0.482175</td>\n",
       "      <td>0.365660</td>\n",
       "      <td>1.764050</td>\n",
       "      <td>-1.104646</td>\n",
       "      <td>-0.787888</td>\n",
       "      <td>-1.091276</td>\n",
       "      <td>-3.244933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390399</th>\n",
       "      <td>3599</td>\n",
       "      <td>499.0</td>\n",
       "      <td>2.791147</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.848543</td>\n",
       "      <td>...</td>\n",
       "      <td>2.868549</td>\n",
       "      <td>2.275890</td>\n",
       "      <td>5.001394</td>\n",
       "      <td>-2.166021</td>\n",
       "      <td>-2.213283</td>\n",
       "      <td>3.781357</td>\n",
       "      <td>0.572082</td>\n",
       "      <td>1.678694</td>\n",
       "      <td>1.795233</td>\n",
       "      <td>0.171858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390400 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   date     weight    resp_1    resp_2    resp_3    resp_4  \\\n",
       "0                 0    0.0   0.000000  0.009916  0.014079  0.008773  0.001390   \n",
       "1                 1    0.0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114   \n",
       "2                 2    0.0   0.000000  0.025134  0.027607  0.033406  0.034380   \n",
       "3                 3    0.0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476   \n",
       "4                 4    0.0   0.138531  0.001252  0.002165 -0.001215 -0.006219   \n",
       "...             ...    ...        ...       ...       ...       ...       ...   \n",
       "2390395        3595  499.0   0.000000  0.000950  0.000950 -0.005755 -0.006558   \n",
       "2390396        3596  499.0   0.501201 -0.000618 -0.000618 -0.015429 -0.077939   \n",
       "2390397        3597  499.0   0.128814  0.008231  0.008231  0.012273  0.031198   \n",
       "2390398        3598  499.0  13.542308  0.001497  0.001497  0.000088 -0.000681   \n",
       "2390399        3599  499.0   2.791147 -0.000015 -0.000015  0.001743  0.009038   \n",
       "\n",
       "             resp  feature_0  feature_1  ...  enc_feature_40  enc_feature_41  \\\n",
       "0        0.006270        1.0  -1.872746  ...       -0.123428        0.628796   \n",
       "1       -0.009792       -1.0  -1.349537  ...       -0.126286        0.982762   \n",
       "2        0.023970       -1.0   0.812780  ...       -3.537209        0.427623   \n",
       "3       -0.003200       -1.0   1.174378  ...       -1.342461        1.185159   \n",
       "4       -0.002604        1.0  -3.172026  ...        0.006980        0.358059   \n",
       "...           ...        ...        ...  ...             ...             ...   \n",
       "2390395 -0.002785        1.0  -2.544545  ...        2.371367        1.537548   \n",
       "2390396 -0.085305        1.0   1.677197  ...        0.737484       -0.531420   \n",
       "2390397  0.031656       -1.0   1.727401  ...       -0.164722        0.643131   \n",
       "2390398  0.001216        1.0  -0.746609  ...        1.125191        2.172657   \n",
       "2390399  0.007601       -1.0  -1.848543  ...        2.868549        2.275890   \n",
       "\n",
       "         enc_feature_42  enc_feature_43  enc_feature_44  enc_feature_45  \\\n",
       "0             -4.023776       -2.183965       -0.077025       -4.211199   \n",
       "1             -0.533399       -0.803045       -1.049025       -1.367514   \n",
       "2             -0.817448        0.061715       -2.020541       -2.091881   \n",
       "3              0.678673        1.851038       -2.856198       -0.807522   \n",
       "4             -2.763735       -0.889712        0.208458       -2.821480   \n",
       "...                 ...             ...             ...             ...   \n",
       "2390395        1.859324        1.114790        2.582138        2.825742   \n",
       "2390396        0.051283       -0.057722        0.434626       -0.072989   \n",
       "2390397        0.073588        4.158679       -0.103347        1.852715   \n",
       "2390398        2.873001        0.482175        0.365660        1.764050   \n",
       "2390399        5.001394       -2.166021       -2.213283        3.781357   \n",
       "\n",
       "         enc_feature_46  enc_feature_47  enc_feature_48  enc_feature_49  \n",
       "0              1.769949       -1.008828       -0.767571        0.848031  \n",
       "1              0.530526       -1.428573        0.224584        0.032676  \n",
       "2             -0.527815        0.721394        1.850761        3.646196  \n",
       "3             -0.994373       -0.755705        0.957583        2.259202  \n",
       "4              0.922953       -1.532228       -0.317601        0.308245  \n",
       "...                 ...             ...             ...             ...  \n",
       "2390395       -0.177744        1.865541       -2.093856       -2.508276  \n",
       "2390396       -1.063528       -0.836696        1.560309       -0.446988  \n",
       "2390397       -0.158158        2.461866       -2.006335        1.108660  \n",
       "2390398       -1.104646       -0.787888       -1.091276       -3.244933  \n",
       "2390399        0.572082        1.678694        1.795233        0.171858  \n",
       "\n",
       "[2390400 rows x 189 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/vaclavmatejka/devel/janestreet/model_8_SDAE_emphasized_loss/encoded.csv\")\n",
    "#df.loc[400:,\"enc_feature_0\":\"enc_feature_49\"]\n",
    "#strip = 1 + df.shape[0] % 200\n",
    "#df.loc[:df.shape[0]-strip]\n",
    "#df[\"enc_feature_0\", \"feature_0\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6380, -1.3042, -2.0674])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1.0,2000.0,3.0])\n",
    "noise = torch.randn_like(t)\n",
    "noise.multiply(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = 1000\n",
    "df = pd.read_csv(\"/home/vaclavmatejka/devel/janestreet/jane-street-market-prediction/train.csv\", nrows=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df.loc[df['resp'] <= 0, 'trade'] = 0\n",
    "df.loc[df['resp'] > 0, 'trade'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420165</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.016171</td>\n",
       "      <td>0.039813</td>\n",
       "      <td>0.061120</td>\n",
       "      <td>0.051909</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.803361</td>\n",
       "      <td>-1.687988</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.735500</td>\n",
       "      <td>-0.603269</td>\n",
       "      <td>-1.588024</td>\n",
       "      <td>-0.614948</td>\n",
       "      <td>-2.783072</td>\n",
       "      <td>-0.882524</td>\n",
       "      <td>-1.890361</td>\n",
       "      <td>-0.789504</td>\n",
       "      <td>-1.662447</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>2.852259</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>-0.019537</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.702446</td>\n",
       "      <td>-1.161989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861067</td>\n",
       "      <td>-0.883083</td>\n",
       "      <td>-0.165111</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>-0.422061</td>\n",
       "      <td>-0.968161</td>\n",
       "      <td>0.167733</td>\n",
       "      <td>-0.920668</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>1.389255</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.006833</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130875</td>\n",
       "      <td>-0.608811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276647</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.269809</td>\n",
       "      <td>-0.036464</td>\n",
       "      <td>0.415885</td>\n",
       "      <td>0.056424</td>\n",
       "      <td>0.422491</td>\n",
       "      <td>-0.036431</td>\n",
       "      <td>0.176114</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085839</td>\n",
       "      <td>-0.003532</td>\n",
       "      <td>-0.037491</td>\n",
       "      <td>-0.053815</td>\n",
       "      <td>-0.052844</td>\n",
       "      <td>-0.065972</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.940655</td>\n",
       "      <td>-0.102939</td>\n",
       "      <td>0.714865</td>\n",
       "      <td>-0.302707</td>\n",
       "      <td>1.022478</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>0.806448</td>\n",
       "      <td>-0.441524</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>1.599537</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>1</td>\n",
       "      <td>1.591598</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193174</td>\n",
       "      <td>0.432659</td>\n",
       "      <td>-0.932680</td>\n",
       "      <td>0.650547</td>\n",
       "      <td>-0.386958</td>\n",
       "      <td>0.491460</td>\n",
       "      <td>-1.032012</td>\n",
       "      <td>0.421468</td>\n",
       "      <td>-0.970129</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0        0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1        0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2        0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3        0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4        0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "...    ...        ...       ...       ...       ...       ...       ...   \n",
       "9995     1   0.420165  0.001847  0.016171  0.039813  0.061120  0.051909   \n",
       "9996     1   2.852259 -0.000712 -0.004864 -0.009795 -0.018601 -0.019537   \n",
       "9997     1   1.389255  0.002383  0.004190  0.002356  0.006833  0.009608   \n",
       "9998     1   0.085839 -0.003532 -0.037491 -0.053815 -0.052844 -0.065972   \n",
       "9999     1   1.599537 -0.001722 -0.001411 -0.000702  0.000706  0.000158   \n",
       "\n",
       "      feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0             1  -1.872746  -2.191242  ...     0.000000     1.168391   \n",
       "1            -1  -1.349537  -1.704709  ...     0.000000    -1.178850   \n",
       "2            -1   0.812780  -0.256156  ...     0.000000     6.115747   \n",
       "3            -1   1.174378   0.344640  ...     0.000000     2.838853   \n",
       "4             1  -3.172026  -3.093182  ...     0.000000     0.344850   \n",
       "...         ...        ...        ...  ...          ...          ...   \n",
       "9995         -1  -0.803361  -1.687988  ...    -2.735500    -0.603269   \n",
       "9996          1  -0.702446  -1.161989  ...    -0.861067    -0.883083   \n",
       "9997          1   0.130875  -0.608811  ...     0.276647    -0.001041   \n",
       "9998          1  -3.172026  -3.093182  ...     0.027756     0.940655   \n",
       "9999          1   1.591598   0.432459  ...    -0.193174     0.432659   \n",
       "\n",
       "      feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0        8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1        1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2        9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3        0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4        4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995    -1.588024    -0.614948    -2.783072    -0.882524    -1.890361   \n",
       "9996    -0.165111    -0.779975    -0.422061    -0.968161     0.167733   \n",
       "9997     0.269809    -0.036464     0.415885     0.056424     0.422491   \n",
       "9998    -0.102939     0.714865    -0.302707     1.022478    -0.315486   \n",
       "9999    -0.932680     0.650547    -0.386958     0.491460    -1.032012   \n",
       "\n",
       "      feature_128  feature_129  ts_id  \n",
       "0        2.301488    11.445807      0  \n",
       "1       -1.304614     1.898684      1  \n",
       "2        6.638248     9.427299      2  \n",
       "3        3.856384     1.013469      3  \n",
       "4        0.362636     3.926633      4  \n",
       "...           ...          ...    ...  \n",
       "9995    -0.789504    -1.662447   9995  \n",
       "9996    -0.920668    -0.010404   9996  \n",
       "9997    -0.036431     0.176114   9997  \n",
       "9998     0.806448    -0.441524   9998  \n",
       "9999     0.421468    -0.970129   9999  \n",
       "\n",
       "[10000 rows x 138 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.sample(frac=1).reset_index()\n",
    "df\n",
    "df.loc[:,\"date\":\"ts_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaneStreetDataset(Dataset):\n",
    "\n",
    "    # Constructor with defult values\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.len = len(self.df)\n",
    "        self.transform = transform\n",
    "\n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = torch.from_numpy(self.df.iloc[index][\"feature_0\":\"feature_129\"].values), torch.tensor(self.df.iloc[index][\"resp\"])\n",
    "        sample = sample[0].to(device), sample[1].to(device)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009634158690232266"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][\"resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -1.13518959e+00, -1.61827057e+00,  4.54450598e-01,\n",
       "        2.80194598e-01,  8.34325776e-01,  6.00991096e-01, -7.52922825e-01,\n",
       "       -7.60245730e-01, -1.26065357e+00, -1.16282365e+00,  3.28691328e-01,\n",
       "        1.57604453e-01, -2.00281266e+00, -1.54143486e+00, -8.06410352e-01,\n",
       "       -1.44557732e+00,  8.54325656e-01,  8.53438605e-01,  2.70115762e-01,\n",
       "        1.22521804e-01,  1.07888779e+00,  4.84688120e-01,  2.30981202e-01,\n",
       "        9.86927946e-02,  2.75536780e-01,  1.03283244e-01, -5.49189303e-01,\n",
       "       -7.48393220e-01, -5.29760682e-01, -4.92395888e-01, -6.75317837e-01,\n",
       "       -1.07180458e+00, -1.06146682e+00, -9.24106051e-01, -7.42370466e-01,\n",
       "       -4.48241035e-01,  1.07317754e+00,  9.00970932e-01, -2.40498460e-01,\n",
       "       -3.47299546e-01,  2.17191018e+00, -3.95957967e-01,  1.14263502e+00,\n",
       "        4.47306184e-01,  5.67436716e-01,  5.70503068e-01,  7.82952089e-01,\n",
       "        4.61510203e-01,  1.99919843e-01,  1.22670170e+00,  2.65245924e+00,\n",
       "        1.34119908e+00, -3.56748341e-01,  1.65067313e-01,  1.81337004e+00,\n",
       "       -4.49947146e-02,  1.99467454e+00,  2.38743882e+00,  2.13005460e+00,\n",
       "       -1.45635570e+00, -1.21888446e+00,  1.67549271e+00,  1.73474684e+00,\n",
       "       -4.30321702e-01,  8.54461748e-01,  7.08229566e-01, -1.07049667e+00,\n",
       "       -1.03096895e+00, -7.27444470e-01, -9.09738630e-01, -9.55175906e-01,\n",
       "        2.43406840e-01, -5.51778306e-01, -9.34265477e-02,  2.22215602e-01,\n",
       "       -5.12737914e-01, -4.76730093e-01,  7.08934320e-01, -7.39138538e-01,\n",
       "       -2.02919110e-01,  4.45906880e-01, -6.94357738e-01, -9.15531721e-01,\n",
       "        3.24548248e-01, -1.23821241e+00, -5.06631054e-02, -3.08182267e-01,\n",
       "       -1.64186017e+00, -1.79339470e-01,  1.14273150e+00, -1.51561349e+00,\n",
       "        4.72040986e-01,  1.93478887e-01, -1.08688642e+00,  7.29592262e-01,\n",
       "        2.44229400e-01,  5.14969891e-01, -1.48970108e-03, -4.58031220e-01,\n",
       "        1.19637572e-01, -1.11841871e-01,  1.17811690e+00,  8.26158486e-01,\n",
       "        4.77704786e-01, -2.85609916e-01,  6.17244401e-01,  8.01955086e-01,\n",
       "        4.22522303e-01, -1.05118881e+00, -1.00639997e-01, -5.72432460e-01,\n",
       "       -1.45037828e+00, -2.03121548e-01,  1.09131958e+00, -2.67911817e-01,\n",
       "        6.23903932e-01, -2.23377279e-01, -6.80334734e-01,  5.80458670e-01,\n",
       "       -8.56725082e-01, -1.78954499e+00, -4.96450008e-01, -2.52105102e-01,\n",
       "       -7.70536965e-01, -1.94612019e+00, -1.16009169e+00, -1.32974511e+00,\n",
       "       -8.65971919e-01, -9.13463219e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][\"feature_0\":\"feature_129\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ae5219358239>:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=130, out_features=500, bias=True)\n",
       "  (1): Dropout(p=0.0, inplace=False)\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Linear(in_features=500, out_features=1000, bias=True)\n",
       "  (5): Dropout(p=0.0, inplace=False)\n",
       "  (6): ReLU()\n",
       "  (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (9): Dropout(p=0.0, inplace=False)\n",
       "  (10): ReLU()\n",
       "  (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (13): Dropout(p=0.0, inplace=False)\n",
       "  (14): ReLU()\n",
       "  (15): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (17): Dropout(p=0.0, inplace=False)\n",
       "  (18): ReLU()\n",
       "  (19): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROPOUT_P = 0.0\n",
    "big_number = 1000\n",
    "small_number = 500\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(130, small_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(small_number),\n",
    "    torch.nn.Linear(small_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, big_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(big_number),\n",
    "    torch.nn.Linear(big_number, small_number),\n",
    "    nn.Dropout(p=DROPOUT_P),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.BatchNorm1d(small_number),\n",
    "    torch.nn.Linear(small_number, 1),\n",
    ")\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "janestreet_train = JaneStreetDataset(df=df.iloc[:-VALIDATION_SIZE])\n",
    "janestreet_validation = JaneStreetDataset(df=df.iloc[-VALIDATION_SIZE:])\n",
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 50\n",
    "LR = 0.05\n",
    "train_loader = torch.utils.data.DataLoader(dataset=janestreet_train, batch_size=BATCH_SIZE, drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=janestreet_validation, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, optimizer, criterion, n_epochs=None):\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.float())\n",
    "            y = y.view(-1, 1).float()\n",
    "            loss = criterion(z, y)\n",
    "            writer.add_scalar(\"Train data\", loss, epoch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.data)\n",
    "        # perform a prediction on the validation data\n",
    "        for x_test, y_test in validation_loader:\n",
    "            model.eval()\n",
    "            z = model(x_test.float())\n",
    "            y = y.view(-1, 1)\n",
    "            loss = criterion(z, y.float())\n",
    "            writer.add_scalar(\"Validation data\", loss, epoch)\n",
    "            accuracy_list.append(loss.data)\n",
    "    return accuracy_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c28e6fbd8523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ea7961b342b8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, validation_loader, optimizer, criterion, n_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-287acf998c17>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"feature_129\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[1;32m   1421\u001b[0m         \u001b[0mCheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;34m'key'\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdesired\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_list, loss_list = train_model(model, train_loader, validation_loader, optimizer, criterion, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=2000\n",
    "#a = torch.from_numpy(df.iloc[index][\"feature_0\":\"feature_129\"].values)\n",
    "a = df.iloc[index][\"feature_0\":\"feature_129\"].values\n",
    "resp = torch.tensor(df.iloc[index][\"resp\"])\n",
    "\n",
    "r = []\n",
    "for one in range(BATCH_SIZE):\n",
    "    r.append(a)\n",
    "r = np.array(r)\n",
    "model_input =torch.from_numpy(r).float().to(device)\n",
    "z = model(model_input)\n",
    "\n",
    "(resp, z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
